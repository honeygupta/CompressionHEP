{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook calculates the memory trace for different variants of the autoencoder model that I had experimented with. \n",
    "\n",
    "* The code calculates the memory blocks occupied while performing data loading and encoding. \n",
    "\n",
    "* The codes were run on a Intel(R) Xeon(R) CPU E5-1620 v4 @ 3.50GHz, which has 8 cores.\n",
    "\n",
    "* Since the code is executed in jupyter, there could be memory overhead due to IPython too, which uniformly affects all the scripts. So the allocation should be considered relatively while drawing any conclusion.\n",
    "\n",
    "\n",
    "***Please note that to calculate the trace for a new model, the notebook should be restarted and a fresh model should be loaded. Re-runing cells or executing same commands within the same kernel changes the memory allocations.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BIN = 'utils/'\n",
    "sys.path.append(BIN)\n",
    "\n",
    "import tracemalloc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import fastai\n",
    "from fastai.callbacks import ActivationStats\n",
    "from fastai import basic_train, basic_data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import my_matplotlib_style as ms\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_utils import AE_3D_200, AE_bn_ELU, AE_bn_LeakyReLU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check memory trace for loading the data and performing normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory allocation: 3.6679 Megabytes\n",
      "\n",
      "/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/pandas/core/internals/managers.py:1848; Size: 2.1322 Megabytes\n",
      "/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/pandas/io/pickle.py:181; Size: 1.0688 Megabytes\n"
     ]
    }
   ],
   "source": [
    "tracemalloc.start()\n",
    "\n",
    "train = pd.read_pickle('../datasets/non_normalized_train_4D_100_percent').astype(np.float32)\n",
    "test = pd.read_pickle('../datasets/non_normalized_test_4D_100_percent').astype(np.float32)\n",
    "\n",
    "# Perform normalization (using standard normalization here)\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "test = (test - train_mean) / train_std\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('lineno')\n",
    "tracemalloc.stop()\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 biggest objects\n",
    "stat = top_stats[0:2]\n",
    "for s in stat:\n",
    "    print(str(s.traceback) + \"; Size: {:.4f}\".format(s.size/(1024*1024)) + \" Megabytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and model to find model memory trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  \n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model with 7 layers, tanh activation, no batch-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE_3D_200()#AE_bn_ELU([4,200,100,50,3,50,100,200,4])\n",
    "loss_func = nn.MSELoss()\n",
    "bn_wd = False  \n",
    "true_wd = True \n",
    "wd = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare database for training\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "#Initialize the trainer\n",
    "learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, wd=wd, callback_fns=ActivationStats, bn_wd=bn_wd, true_wd=true_wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_3D_200(\n",
       "  (en1): Linear(in_features=4, out_features=200, bias=True)\n",
       "  (en2): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (en3): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (en4): Linear(in_features=50, out_features=3, bias=True)\n",
       "  (de1): Linear(in_features=3, out_features=50, bias=True)\n",
       "  (de2): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (de3): Linear(in_features=100, out_features=200, bias=True)\n",
       "  (de4): Linear(in_features=200, out_features=4, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('AE_3D_200_no1cycle_std_norm')\n",
    "\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check memory trace for encoding and decoding the entire test set\n",
    "The test set contains 27945 samples. The following code calculates the memory trace of the encoding operation of the model. It prints the total memory space occupied and the top few objects memory-allocation-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "Total memory allocation: 0.0024 Megabytes\n",
      "\n",
      "1 memory blocks: 0.5 KiB\n",
      "['  File \"utils/nn_utils.py\", line 126', '    m1 = self.en1(x)']\n",
      "1 memory blocks: 0.4 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532', '    result = self.forward(*input, **kwargs)']\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('traceback')\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 objects according to their memory block allocation\n",
    "for i in range(2):\n",
    "    stat = top_stats[i]\n",
    "    print(\"%s memory blocks: %.1f KiB\" % (stat.count, stat.size / 1024))\n",
    "    print([line for line in stat.traceback.format()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "Total memory allocation: 0.1780 Megabytes\n",
      "\n",
      "1330 memory blocks: 136.3 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/linecache.py\", line 137', '    lines = fp.readlines()']\n",
      "308 memory blocks: 15.0 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/compilerop.py\", line 101', '    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)']\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "reconstructed = learn.model.decode(torch.tensor(compressed)).detach().numpy()\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('traceback')\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 objects according to their memory block allocation\n",
    "for i in range(2):\n",
    "    stat = top_stats[i]\n",
    "    print(\"%s memory blocks: %.1f KiB\" % (stat.count, stat.size / 1024))\n",
    "    print([line for line in stat.traceback.format()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 layer model with LeakyReLU and batch-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and model to find model memory trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE_bn_LeakyReLU([4,200,100,50,3,50,100,200,4])\n",
    "loss_func = nn.MSELoss()\n",
    "bn_wd = False  \n",
    "true_wd = True \n",
    "wd = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare database for training\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "#Initialize the trainer\n",
    "learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, wd=wd, callback_fns=ActivationStats, bn_wd=bn_wd, true_wd=true_wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_bn_LeakyReLU(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=200, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=50, out_features=3, bias=True)\n",
       "    (10): LeakyReLU(negative_slope=0.01)\n",
       "    (11): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=200, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('AE_3D_200_ReLU_BN_custom_norm')\n",
    "\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "Total memory allocation: 0.0076 Megabytes\n",
      "\n",
      "4 memory blocks: 1.8 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532', '    result = self.forward(*input, **kwargs)']\n",
      "3 memory blocks: 0.6 KiB\n",
      "['  File \"<ipython-input-8-416b51b8dfab>\", line 6', '    compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()']\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('traceback')\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 objects according to their memory block allocation\n",
    "for i in range(2):\n",
    "    stat = top_stats[i]\n",
    "    print(\"%s memory blocks: %.1f KiB\" % (stat.count, stat.size / 1024))\n",
    "    print([line for line in stat.traceback.format()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "Total memory allocation: 0.2240 Megabytes\n",
      "\n",
      "1550 memory blocks: 157.5 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/linecache.py\", line 137', '    lines = fp.readlines()']\n",
      "356 memory blocks: 18.3 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/compilerop.py\", line 101', '    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)']\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "reconstructed = learn.model.decode(torch.tensor(compressed)).detach().numpy()\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('traceback')\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 objects according to their memory block allocation\n",
    "for i in range(2):\n",
    "    stat = top_stats[i]\n",
    "    print(\"%s memory blocks: %.1f KiB\" % (stat.count, stat.size / 1024))\n",
    "    print([line for line in stat.traceback.format()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 layer model with ELU and batch-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and model to find model memory trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AE_bn_ELU([4,200,100,50,3,50,100,200,4])\n",
    "loss_func = nn.MSELoss()\n",
    "bn_wd = False  \n",
    "true_wd = True \n",
    "wd = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare database for training\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "#Initialize the trainer\n",
    "learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, wd=wd, callback_fns=ActivationStats, bn_wd=bn_wd, true_wd=true_wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_bn_ELU(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=200, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (4): ELU(alpha=1.0)\n",
       "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (7): ELU(alpha=1.0)\n",
       "    (8): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=50, out_features=3, bias=True)\n",
       "    (10): ELU(alpha=1.0)\n",
       "    (11): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=50, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (4): ELU(alpha=1.0)\n",
       "    (5): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (7): ELU(alpha=1.0)\n",
       "    (8): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Linear(in_features=200, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load('AE_3D_200_ELU_BN_custom_norm')\n",
    "\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "Total memory allocation: 0.0064 Megabytes\n",
      "\n",
      "3 memory blocks: 1.4 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532', '    result = self.forward(*input, **kwargs)']\n",
      "1 memory blocks: 0.6 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\", line 107', '    exponential_average_factor, self.eps)']\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('traceback')\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 objects according to their memory block allocation\n",
    "for i in range(2):\n",
    "    stat = top_stats[i]\n",
    "    print(\"%s memory blocks: %.1f KiB\" % (stat.count, stat.size / 1024))\n",
    "    print([line for line in stat.traceback.format()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "Total memory allocation: 0.1945 Megabytes\n",
      "\n",
      "1381 memory blocks: 148.3 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/linecache.py\", line 137', '    lines = fp.readlines()']\n",
      "309 memory blocks: 15.0 KiB\n",
      "['  File \"/home/honey/miniconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/compilerop.py\", line 101', '    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)']\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "reconstructed = learn.model.decode(torch.tensor(compressed)).detach().numpy()\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "top_stats = snapshot.statistics('traceback')\n",
    "\n",
    "# Print the total memory allocation traced\n",
    "stat = top_stats\n",
    "total_size = 0\n",
    "for s in stat:\n",
    "    total_size += s.size/(1024*1024)\n",
    "print(\"Total memory allocation: {:.4f}\".format(total_size) + \" Megabytes\")\n",
    "print()\n",
    "\n",
    "# Pick the 2 objects according to their memory block allocation\n",
    "for i in range(2):\n",
    "    stat = top_stats[i]\n",
    "    print(\"%s memory blocks: %.1f KiB\" % (stat.count, stat.size / 1024))\n",
    "    print([line for line in stat.traceback.format()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
