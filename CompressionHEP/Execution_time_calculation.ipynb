{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook calculates the execution time for different parts of the project. \n",
    "\n",
    "* The codes were run on a Intel(R) Xeon(R) CPU E5-1620 v4 @ 3.50GHz, which has 8 cores.\n",
    "\n",
    "***Please note that to calculate the time for different parts, the notebook should be restarted. Re-reunning cells or executing same commands within the same kernel can change execution time.***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BIN = 'utils/'\n",
    "sys.path.append(BIN)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import fastai\n",
    "from fastai.callbacks import ActivationStats\n",
    "from fastai import basic_train, basic_data\n",
    "\n",
    "import matplotlib as mpl\n",
    "import my_matplotlib_style as ms\n",
    "mpl.rc_file(BIN + 'my_matplotlib_rcparams')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_utils import AE_3D_200, AE_bn_ELU, AE_bn_LeakyReLU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check execution time for loading the data and performing normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.10176873207092285 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "train = pd.read_pickle('../datasets/non_normalized_train_4D_100_percent').astype(np.float32)\n",
    "test = pd.read_pickle('../datasets/non_normalized_test_4D_100_percent').astype(np.float32)\n",
    "\n",
    "# Perform normalization (using standard normalization here)\n",
    "train_mean = train.mean()\n",
    "train_std = train.std()\n",
    "\n",
    "train = (train - train_mean) / train_std\n",
    "test = (test - train_mean) / train_std\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.00497889518737793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "train_x = train\n",
    "test_x = test\n",
    "train_y = train_x  \n",
    "test_y = test_x\n",
    "\n",
    "train_ds = TensorDataset(torch.tensor(train_x.values), torch.tensor(train_y.values))\n",
    "valid_ds = TensorDataset(torch.tensor(test_x.values), torch.tensor(test_y.values))\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs=256)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model with 7 layers, tanh activation, no batch-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.517495632171631 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "model = AE_3D_200()#AE_bn_ELU([4,200,100,50,3,50,100,200,4])\n",
    "loss_func = nn.MSELoss()\n",
    "bn_wd = False  \n",
    "true_wd = True \n",
    "wd = 1e-6\n",
    "\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "#Initialize the trainer\n",
    "learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, wd=wd, callback_fns=ActivationStats, bn_wd=bn_wd, true_wd=true_wd)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.059327125549316406 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "learn.load('AE_3D_200_no1cycle_std_norm')\n",
    "model.to('cpu')\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for encoding and decoding the entire test-set\n",
    "The test set contains 27945 samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "--- 0.03934311866760254 seconds ---\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "--- 0.021132469177246094 seconds ---\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "compressed = learn.model.decode(torch.tensor(compressed)).detach().numpy()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 layer model with LeakyReLU and batch-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.590345621109009 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "model = AE_bn_LeakyReLU([4,200,100,50,3,50,100,200,4])\n",
    "loss_func = nn.MSELoss()\n",
    "bn_wd = False  \n",
    "true_wd = True \n",
    "wd = 1e-6\n",
    "\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "#Initialize the trainer\n",
    "learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, wd=wd, callback_fns=ActivationStats, bn_wd=bn_wd, true_wd=true_wd)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.08180046081542969 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "learn.load('AE_3D_200_ReLU_BN_custom_norm')\n",
    "model.to('cpu')\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for encoding and decoding the entire test-set\n",
    "The test set contains 27945 samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "--- 0.12612652778625488 seconds ---\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "--- 0.10033035278320312 seconds ---\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "compressed = learn.model.decode(torch.tensor(compressed)).detach().numpy()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 layer model with ELU and batch-norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.437354326248169 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "model = AE_bn_ELU([4,200,100,50,3,50,100,200,4])\n",
    "loss_func = nn.MSELoss()\n",
    "bn_wd = False  \n",
    "true_wd = True \n",
    "wd = 1e-6\n",
    "\n",
    "db = basic_data.DataBunch(train_dl, valid_dl)\n",
    "\n",
    "#Initialize the trainer\n",
    "learn = basic_train.Learner(data=db, model=model, loss_func=loss_func, wd=wd, callback_fns=ActivationStats, bn_wd=bn_wd, true_wd=true_wd)\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.07940340042114258 seconds ---\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "learn.load('AE_3D_200_ELU_BN_custom_norm')\n",
    "model.to('cpu')\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time for encoding and decoding the entire test-set\n",
    "The test set contains 27945 samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "--- 0.16376805305480957 seconds ---\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "compressed = learn.model.encode(torch.tensor(test.values)).detach().numpy()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events: 27945\n",
      "--- 0.1523725986480713 seconds ---\n"
     ]
    }
   ],
   "source": [
    "number_of_events = torch.tensor(test.values).size()[0]\n",
    "print(\"Number of events: \" + str(number_of_events))\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "compressed = learn.model.decode(torch.tensor(compressed)).detach().numpy()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"--- %s seconds ---\" % (toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
